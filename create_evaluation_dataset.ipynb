{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharth/anaconda3/envs/11-632/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_directory = os.path.abspath('') + \"/repository\"\n",
    "models_jsons = os.listdir(repository_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_model_dict = {}\n",
    "\n",
    "for model_file in models_jsons:\n",
    "    with open(repository_directory + \"/\" + model_file) as model_json:\n",
    "        data = json.load(model_json)\n",
    "        for dataset in data['dataset']:\n",
    "            if dataset not in dataset_model_dict:\n",
    "                dataset_model_dict[dataset] = []\n",
    "            \n",
    "            dataset_model_dict[dataset].append(data['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_model_dict = {}\n",
    "\n",
    "for model_file in models_jsons:\n",
    "    with open(repository_directory + \"/\" + model_file) as model_json:\n",
    "        data = json.load(model_json)\n",
    "        for domain in data['domain']:\n",
    "            if domain not in domain_model_dict:\n",
    "                domain_model_dict[domain] = []\n",
    "            \n",
    "            domain_model_dict[domain].append(data['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dataset_dict = {}\n",
    "\n",
    "for model_file in models_jsons:\n",
    "    with open(repository_directory + \"/\" + model_file) as model_json:\n",
    "        data = json.load(model_json)\n",
    "        domain = data['domain'][0]\n",
    "        for dt in data['dataset']:\n",
    "            if domain not in domain_dataset_dict:\n",
    "                domain_dataset_dict[domain] = []\n",
    "            \n",
    "            domain_dataset_dict[domain].append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'None': ['mrm8488/longformer-base-4096-finetuned-squadv2',\n",
       "  'allenai/longformer-large-4096-finetuned-triviaqa',\n",
       "  'allenai/unifiedqa-t5-base'],\n",
       " 'math': ['AdapterHub/roberta-base-pf-hotpotqa',\n",
       "  'AlexWortega/taskGPT2-xl-v0.2a',\n",
       "  'vanadhi/roberta-base-fiqa-flm-sq-flit'],\n",
       " 'legal': ['Rakib/roberta-base-on-cuad', 'akdeniz27/deberta-v2-xlarge-cuad'],\n",
       " 'bio': ['ozcangundes/T5-base-for-BioQA',\n",
       "  'microsoft/biogpt',\n",
       "  'Sarmila/pubmed-bert-squad-covidqa'],\n",
       " 'narrative': ['MaRiOrOsSi/t5-base-finetuned-question-answering'],\n",
       " 'science': ['razent/SciFive-base-Pubmed_PMC', 'ixa-ehu/SciBERT-SQuAD-QuAC'],\n",
       " 'finance': ['vanadhi/roberta-base-fiqa-flm-sq-flit']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'squad_v2': ['mrm8488/longformer-base-4096-finetuned-squadv2',\n",
       "  'allenai/unifiedqa-t5-base',\n",
       "  'ixa-ehu/SciBERT-SQuAD-QuAC'],\n",
       " 'hotpot_qa': ['AdapterHub/roberta-base-pf-hotpotqa'],\n",
       " 'cuad': ['Rakib/roberta-base-on-cuad', 'akdeniz27/deberta-v2-xlarge-cuad'],\n",
       " 'trivia_qa': ['allenai/longformer-large-4096-finetuned-triviaqa'],\n",
       " 'squad': ['ozcangundes/T5-base-for-BioQA',\n",
       "  'MaRiOrOsSi/t5-base-finetuned-question-answering',\n",
       "  'vanadhi/roberta-base-fiqa-flm-sq-flit'],\n",
       " 'BeIR/bioasq-generated-queries': ['ozcangundes/T5-base-for-BioQA'],\n",
       " 'duorc': ['MaRiOrOsSi/t5-base-finetuned-question-answering',\n",
       "  'MaRiOrOsSi/t5-base-finetuned-question-answering'],\n",
       " 'pubmed_qa': ['razent/SciFive-base-Pubmed_PMC', 'microsoft/biogpt'],\n",
       " 'zhengyun21/PMC-Patients': ['razent/SciFive-base-Pubmed_PMC'],\n",
       " 'boolq': ['allenai/unifiedqa-t5-base'],\n",
       " 'race': ['allenai/unifiedqa-t5-base'],\n",
       " 'quoref': ['allenai/unifiedqa-t5-base'],\n",
       " 'ropes': ['allenai/unifiedqa-t5-base'],\n",
       " 'drop': ['allenai/unifiedqa-t5-base'],\n",
       " 'sagnikrayc/mctest': ['allenai/unifiedqa-t5-base'],\n",
       " 'qasc': ['allenai/unifiedqa-t5-base'],\n",
       " 'math_qa': ['AlexWortega/taskGPT2-xl-v0.2a'],\n",
       " 'gsm8k': ['AlexWortega/taskGPT2-xl-v0.2a'],\n",
       " 'covid_qa_deepset': ['Sarmila/pubmed-bert-squad-covidqa'],\n",
       " 'quac': ['ixa-ehu/SciBERT-SQuAD-QuAC']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rows_from_dataset(dataset: str,\n",
    "                             column_names: tuple,\n",
    "                             *args,\n",
    "                             num_samples: int = 250,\n",
    "                             seed: int = 121,\n",
    "                             **kwargs) -> pd.DataFrame:    \n",
    "    if not isinstance(column_names, tuple):\n",
    "        raise Exception(\"Column names need to be a list of column names as strings.\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset, *args, split=\"test\")\n",
    "    except Exception as e:\n",
    "        print(\"Could NOT load dataset for {0}\".format(dataset))\n",
    "        raise Exception(\"Error while loading dataset {}\".format(e))\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed)\n",
    "    df = pd.DataFrame(shuffled_dataset[:num_samples])\n",
    "    try:\n",
    "        return df[list(column_names)]\n",
    "    except KeyError as e:\n",
    "        raise e\n",
    "    \n",
    "    \n",
    "def sample_rows_from_dataset(dataset: str,\n",
    "                             column_names: tuple,\n",
    "                             *args,\n",
    "                             num_samples: int = 2000,\n",
    "                             seed: int = 121,\n",
    "                             **kwargs) -> pd.DataFrame:\n",
    "    if not isinstance(column_names, tuple):\n",
    "        raise Exception(\"Column names need to be a list of column names as strings.\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset, *args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(\"Could NOT load dataset for {0}\".format(dataset))\n",
    "        raise Exception(\"Error while loading dataset {}\".format(e))\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed)\n",
    "    df = pd.DataFrame(shuffled_dataset[:num_samples])\n",
    "    try:\n",
    "        return df[list(column_names)]\n",
    "    except KeyError as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"squad\"\n",
    "configs = None\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "\n",
    "squad_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_qa_dataset = squad_qa_dataset.head(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for i in range(len(squad_qa_dataset)):\n",
    "    curr_ans_list = squad_qa_dataset['answers'][i]['text']\n",
    "    curr_ans = max(curr_ans_list, key = len)\n",
    "    answers.append(curr_ans)\n",
    "    \n",
    "squad_qa_dataset['answers'] = answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pubmed Biology Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"pubmed_qa\"\n",
    "config = \"pqa_labeled\"\n",
    "column_tuple = (\"question\", \"context\", \"long_answer\")\n",
    "\n",
    "pubmed_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, config, split=\"train\")\n",
    "\n",
    "contexts_strings = []\n",
    "\n",
    "for i in range(len(pubmed_qa_dataset)):\n",
    "    contexts_strings.append(' '.join(pubmed_qa_dataset[\"context\"][i]['contexts']))\n",
    "    \n",
    "pubmed_qa_dataset['context'] = contexts_strings\n",
    "pubmed_qa_dataset = pubmed_qa_dataset.rename(columns={\"long_answer\": \"answers\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_qa_dataset = pubmed_qa_dataset.head(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioASQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 14.0k/14.0k [00:00<00:00, 40.1MB/s]\n",
      "Downloading data: 100%|██████████| 7.12G/7.12G [09:22<00:00, 12.7MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [09:22<00:00, 562.45s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [01:16<00:00, 76.97s/it]\n",
      "Generating train split: 14100000 examples [01:29, 158196.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"BeIR/bioasq-generated-queries\"\n",
    "column_tuple = (\"text\", \"query\")\n",
    "\n",
    "bioasq_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")\n",
    "bioasq_qa_dataset = bioasq_qa_dataset.rename(columns={\"text\": \"context\", \"query\": \"question\"})\n",
    "bioasq_qa_dataset = bioasq_qa_dataset[[\"question\", \"context\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuad (legal) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cuad\"\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "\n",
    "cuad_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for i in range(len(cuad_qa_dataset)):\n",
    "    curr_ans_list = cuad_qa_dataset['answers'][i]['text']\n",
    "    if len(curr_ans_list)!=0:\n",
    "        curr_ans = max(curr_ans_list, key = len)\n",
    "    else:\n",
    "        curr_ans = \"\"\n",
    "    answers.append(curr_ans)\n",
    "    \n",
    "cuad_qa_dataset['answers'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuad_qa_dataset = cuad_qa_dataset[cuad_qa_dataset[\"answers\"]!=\"\"][:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"sciq\"\n",
    "column_tuple = (\"question\", \"support\", \"correct_answer\")\n",
    "\n",
    "sciq_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciq_qa_dataset = sciq_qa_dataset.rename(columns={\"support\": \"context\", \"correct_answer\": \"answers\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciq_qa_dataset = sciq_qa_dataset.head(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CovidQA Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"covid_qa_deepset\"\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "\n",
    "covidqa_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['zanamivir (Relenza) and oseltamivir (Tamiflu)'],\n",
       " 'answer_start': [2356]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covidqa_qa_dataset['answers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for i in range(len(covidqa_qa_dataset)):\n",
    "    curr_ans_list = covidqa_qa_dataset['answers'][i]['text']\n",
    "    if len(curr_ans_list)!=0:\n",
    "        curr_ans = max(curr_ans_list, key = len)\n",
    "    else:\n",
    "        curr_ans = \"\"\n",
    "    answers.append(curr_ans)\n",
    "    \n",
    "covidqa_qa_dataset['answers'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidqa_qa_dataset = covidqa_qa_dataset.head(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuad_qa_dataset[\"domain\"] = \"legal\"\n",
    "#bioasq_qa_dataset[\"domain\"] = \"bio\"\n",
    "pubmed_qa_dataset[\"domain\"] = \"bio\"\n",
    "squad_qa_dataset[\"domain\"] = \"None\"\n",
    "sciq_qa_dataset[\"domain\"] = \"science\"\n",
    "covidqa_qa_dataset[\"domain\"] = \"bio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_list = dataset_model_dict['quac'] + dataset_model_dict['zhengyun21/PMC-Patients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_list = dataset_model_dict['BeIR/bioasq-generated-queries'] + dataset_model_dict['pubmed_qa'] + dataset_model_dict['covid_qa_deepset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuad_qa_dataset['models'] = \"\"\n",
    "pubmed_qa_dataset['models'] = \"\"\n",
    "squad_qa_dataset['models'] = \"\"\n",
    "sciq_qa_dataset['models'] = \"\"\n",
    "covidqa_qa_dataset['models'] = \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuad_qa_dataset['models'] = cuad_qa_dataset['models'].apply(lambda x: domain_model_dict['legal'])\n",
    "pubmed_qa_dataset['models'] = pubmed_qa_dataset['models'].apply(lambda x: domain_model_dict['bio'])\n",
    "squad_qa_dataset['models'] = squad_qa_dataset['models'].apply(lambda x: domain_model_dict['None'])\n",
    "sciq_qa_dataset['models'] = sciq_qa_dataset['models'].apply(lambda x: domain_model_dict['science'])\n",
    "covidqa_qa_dataset['models'] = covidqa_qa_dataset['models'].apply(lambda x: domain_model_dict['bio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pd.concat([cuad_qa_dataset, pubmed_qa_dataset, squad_qa_dataset, sciq_qa_dataset, covidqa_qa_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = eval_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.to_csv(\"eval_dataset_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"eval_dataset_v2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11-632",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
