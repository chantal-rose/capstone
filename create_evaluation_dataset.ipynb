{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_directory = os.path.abspath('') + \"/repository\"\n",
    "models_jsons = os.listdir(repository_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_model_dict = {}\n",
    "\n",
    "for model_file in models_jsons:\n",
    "    with open(repository_directory + \"/\" + model_file) as model_json:\n",
    "        data = json.load(model_json)\n",
    "        for dataset in data['dataset']:\n",
    "            if dataset not in dataset_model_dict:\n",
    "                dataset_model_dict[dataset] = []\n",
    "            \n",
    "            dataset_model_dict[dataset].append(data['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_model_dict = {}\n",
    "\n",
    "for model_file in models_jsons:\n",
    "    with open(repository_directory + \"/\" + model_file) as model_json:\n",
    "        data = json.load(model_json)\n",
    "        for domain in data['domain']:\n",
    "            if domain not in domain_model_dict:\n",
    "                domain_model_dict[domain] = []\n",
    "            \n",
    "            domain_model_dict[domain].append(data['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dataset_dict = {}\n",
    "\n",
    "for model_file in models_jsons:\n",
    "    with open(repository_directory + \"/\" + model_file) as model_json:\n",
    "        data = json.load(model_json)\n",
    "        domain = data['domain'][0]\n",
    "        for dt in data['dataset']:\n",
    "            if domain not in domain_dataset_dict:\n",
    "                domain_dataset_dict[domain] = []\n",
    "            \n",
    "            domain_dataset_dict[domain].append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'None': ['mrm8488/longformer-base-4096-finetuned-squadv2',\n",
       "  'allenai/longformer-large-4096-finetuned-triviaqa',\n",
       "  'allenai/unifiedqa-t5-base'],\n",
       " 'math': ['AdapterHub/roberta-base-pf-hotpotqa',\n",
       "  'AlexWortega/taskGPT2-xl-v0.2a',\n",
       "  'vanadhi/roberta-base-fiqa-flm-sq-flit'],\n",
       " 'legal': ['Rakib/roberta-base-on-cuad', 'akdeniz27/deberta-v2-xlarge-cuad'],\n",
       " 'bio': ['ozcangundes/T5-base-for-BioQA',\n",
       "  'microsoft/biogpt',\n",
       "  'Sarmila/pubmed-bert-squad-covidqa'],\n",
       " 'narrative': ['MaRiOrOsSi/t5-base-finetuned-question-answering'],\n",
       " 'science': ['razent/SciFive-base-Pubmed_PMC', 'ixa-ehu/SciBERT-SQuAD-QuAC'],\n",
       " 'finance': ['vanadhi/roberta-base-fiqa-flm-sq-flit']}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rows_from_dataset(dataset: str,\n",
    "                             column_names: tuple,\n",
    "                             *args,\n",
    "                             num_samples: int = 250,\n",
    "                             seed: int = 1001,\n",
    "                             **kwargs) -> pd.DataFrame:    \n",
    "    if not isinstance(column_names, tuple):\n",
    "        raise Exception(\"Column names need to be a list of column names as strings.\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset, *args, split=\"test\")\n",
    "    except Exception as e:\n",
    "        print(\"Could NOT load dataset for {0}\".format(dataset))\n",
    "        raise Exception(\"Error while loading dataset {}\".format(e))\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed)\n",
    "    df = pd.DataFrame(shuffled_dataset[:num_samples])\n",
    "    try:\n",
    "        return df[list(column_names)]\n",
    "    except KeyError as e:\n",
    "        raise e\n",
    "    \n",
    "    \n",
    "def sample_rows_from_dataset(dataset: str,\n",
    "                             column_names: tuple,\n",
    "                             *args,\n",
    "                             num_samples: int = 2000,\n",
    "                             seed: int = 1001,\n",
    "                             **kwargs) -> pd.DataFrame:\n",
    "    if not isinstance(column_names, tuple):\n",
    "        raise Exception(\"Column names need to be a list of column names as strings.\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset, *args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(\"Could NOT load dataset for {0}\".format(dataset))\n",
    "        raise Exception(\"Error while loading dataset {}\".format(e))\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed)\n",
    "    df = pd.DataFrame(shuffled_dataset[:num_samples])\n",
    "    try:\n",
    "        return df[list(column_names)]\n",
    "    except KeyError as e:\n",
    "        raise e\n",
    "    \n",
    "def extract_answer_from_list(dataset, answer_column, answer_column_json_key):\n",
    "    answers = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        curr_ans_list = dataset[answer_column][i][answer_column_json_key]\n",
    "        if len(curr_ans_list)==0:\n",
    "            curr_ans = \"\"\n",
    "        else:\n",
    "            curr_ans = max(curr_ans_list, key = len)\n",
    "            \n",
    "        answers.append(curr_ans)\n",
    "        \n",
    "    dataset[\"answer\"] = answers\n",
    "    return dataset\n",
    "    \n",
    "def extract_relevant_columns(dataset, columns):\n",
    "    return dataset[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"squad\"\n",
    "configs = None\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "\n",
    "squad_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Western was a flagship program for ABC ar...</td>\n",
       "      <td>At the same time he made attempts to help grow...</td>\n",
       "      <td>{'text': ['The Lone Ranger', 'The Lone Ranger'...</td>\n",
       "      <td>The Lone Ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What types of scientists looks for signs of ma...</td>\n",
       "      <td>In the laboratory, biostratigraphers analyze r...</td>\n",
       "      <td>{'text': ['Magnetic stratigraphers', 'Magnetic...</td>\n",
       "      <td>Magnetic stratigraphers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What happened in 1901?</td>\n",
       "      <td>In December 1901, Marconi successfully transmi...</td>\n",
       "      <td>{'text': ['Marconi successfully transmitted th...</td>\n",
       "      <td>Marconi successfully transmitted the letter S ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was the name of France's primary colony i...</td>\n",
       "      <td>The exodus of Huguenots from France created a ...</td>\n",
       "      <td>{'text': ['New France', 'New France', 'New Fra...</td>\n",
       "      <td>New France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is not considered appropriate disclipine?</td>\n",
       "      <td>A modern example of school discipline in North...</td>\n",
       "      <td>{'text': ['sarcasm and attempts to humiliate p...</td>\n",
       "      <td>sarcasm and attempts to humiliate pupils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>What type of treaty was the Lisbon Treaty?</td>\n",
       "      <td>Following the Nice Treaty, there was an attemp...</td>\n",
       "      <td>{'text': ['an amending treaty', 'an amending t...</td>\n",
       "      <td>an amending treaty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>What is the term that describes the difference...</td>\n",
       "      <td>Neoclassical economics views inequalities in t...</td>\n",
       "      <td>{'text': ['productivity gap', 'productivity ga...</td>\n",
       "      <td>productivity gap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>In which region tribe were large settlements d...</td>\n",
       "      <td>Terra preta (black earth), which is distribute...</td>\n",
       "      <td>{'text': ['Xingu tribe', 'Xingu', 'Xingu'], 'a...</td>\n",
       "      <td>Xingu tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Where are some physicians permitted to prescri...</td>\n",
       "      <td>In some rural areas in the United Kingdom, the...</td>\n",
       "      <td>{'text': ['In some rural areas in the United K...</td>\n",
       "      <td>prescribe and dispense prescription-only medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>What was the last Doctor Who episode that Dudl...</td>\n",
       "      <td>The most frequent musical contributor during t...</td>\n",
       "      <td>{'text': ['The Horns of Nimon', 'The Horns of ...</td>\n",
       "      <td>The Horns of Nimon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     What Western was a flagship program for ABC ar...   \n",
       "1     What types of scientists looks for signs of ma...   \n",
       "2                                What happened in 1901?   \n",
       "3     What was the name of France's primary colony i...   \n",
       "4        What is not considered appropriate disclipine?   \n",
       "...                                                 ...   \n",
       "1995         What type of treaty was the Lisbon Treaty?   \n",
       "1996  What is the term that describes the difference...   \n",
       "1997  In which region tribe were large settlements d...   \n",
       "1998  Where are some physicians permitted to prescri...   \n",
       "1999  What was the last Doctor Who episode that Dudl...   \n",
       "\n",
       "                                                context  \\\n",
       "0     At the same time he made attempts to help grow...   \n",
       "1     In the laboratory, biostratigraphers analyze r...   \n",
       "2     In December 1901, Marconi successfully transmi...   \n",
       "3     The exodus of Huguenots from France created a ...   \n",
       "4     A modern example of school discipline in North...   \n",
       "...                                                 ...   \n",
       "1995  Following the Nice Treaty, there was an attemp...   \n",
       "1996  Neoclassical economics views inequalities in t...   \n",
       "1997  Terra preta (black earth), which is distribute...   \n",
       "1998  In some rural areas in the United Kingdom, the...   \n",
       "1999  The most frequent musical contributor during t...   \n",
       "\n",
       "                                                answers  \\\n",
       "0     {'text': ['The Lone Ranger', 'The Lone Ranger'...   \n",
       "1     {'text': ['Magnetic stratigraphers', 'Magnetic...   \n",
       "2     {'text': ['Marconi successfully transmitted th...   \n",
       "3     {'text': ['New France', 'New France', 'New Fra...   \n",
       "4     {'text': ['sarcasm and attempts to humiliate p...   \n",
       "...                                                 ...   \n",
       "1995  {'text': ['an amending treaty', 'an amending t...   \n",
       "1996  {'text': ['productivity gap', 'productivity ga...   \n",
       "1997  {'text': ['Xingu tribe', 'Xingu', 'Xingu'], 'a...   \n",
       "1998  {'text': ['In some rural areas in the United K...   \n",
       "1999  {'text': ['The Horns of Nimon', 'The Horns of ...   \n",
       "\n",
       "                                                 answer  \n",
       "0                                       The Lone Ranger  \n",
       "1                               Magnetic stratigraphers  \n",
       "2     Marconi successfully transmitted the letter S ...  \n",
       "3                                            New France  \n",
       "4              sarcasm and attempts to humiliate pupils  \n",
       "...                                                 ...  \n",
       "1995                                 an amending treaty  \n",
       "1996                                   productivity gap  \n",
       "1997                                        Xingu tribe  \n",
       "1998  prescribe and dispense prescription-only medic...  \n",
       "1999                                 The Horns of Nimon  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answer_from_list(squad_qa_dataset, \"answers\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pubmed Biology Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"pubmed_qa\"\n",
    "config = \"pqa_labeled\"\n",
    "column_tuple = (\"question\", \"context\", \"long_answer\")\n",
    "\n",
    "pubmed_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, config, split=\"train\")\n",
    "\n",
    "contexts_strings = []\n",
    "\n",
    "for i in range(len(pubmed_qa_dataset)):\n",
    "    contexts_strings.append(' '.join(pubmed_qa_dataset[\"context\"][i]['contexts']))\n",
    "    \n",
    "pubmed_qa_dataset['context'] = contexts_strings\n",
    "pubmed_qa_dataset = pubmed_qa_dataset.rename(columns={\"long_answer\": \"answer\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioASQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_dataset = pd.read_csv(\"bioasq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_dataset = bioasq_dataset.rename(columns={\"Question\": \"question\", \"Context\":\"context\", \"Answer\":\"answer\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"sciq\"\n",
    "column_tuple = (\"question\", \"support\", \"correct_answer\")\n",
    "\n",
    "sciq_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciq_qa_dataset = sciq_qa_dataset.rename(columns={\"support\": \"context\", \"correct_answer\": \"answer\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CovidQA Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"covid_qa_deepset\"\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "\n",
    "covidqa_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is this approach significant?</td>\n",
       "      <td>Respiratory Viral Infections in Exacerbation o...</td>\n",
       "      <td>{'text': ['due to the current scarcity of anti...</td>\n",
       "      <td>due to the current scarcity of antiviral drugs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When was SARS-CoV first identified?</td>\n",
       "      <td>Host resilience to emerging coronaviruses\\n\\nh...</td>\n",
       "      <td>{'text': ['2003'], 'answer_start': [1375]}</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the amino acid similarity between IFIT...</td>\n",
       "      <td>Role of S-Palmitoylation on IFITM5 for the Int...</td>\n",
       "      <td>{'text': ['~ 65% similarity'], 'answer_start':...</td>\n",
       "      <td>~ 65% similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What family of virus does MERS reside in?</td>\n",
       "      <td>Host resilience to emerging coronaviruses\\n\\nh...</td>\n",
       "      <td>{'text': ['coronavirus'], 'answer_start': [1018]}</td>\n",
       "      <td>coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can a semi-mechanistic Bayesian hierarchic...</td>\n",
       "      <td>Estimating the number of infections and the im...</td>\n",
       "      <td>{'text': ['calculating backwards from the deat...</td>\n",
       "      <td>calculating backwards from the deaths observed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Patients from how many medical centers were st...</td>\n",
       "      <td>Which Kind of Provider’s Operation Volumes Mat...</td>\n",
       "      <td>{'text': ['19'], 'answer_start': [9132]}</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>What domembers of the Roquin and Regnase famil...</td>\n",
       "      <td>Frontiers in antiviral therapy and immunothera...</td>\n",
       "      <td>{'text': ['promote or effect degradation of mR...</td>\n",
       "      <td>promote or effect degradation of mRNAs harbour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>What did the study report?</td>\n",
       "      <td>Chikungunya: A Potentially Emerging Epidemic?\\...</td>\n",
       "      <td>{'text': ['neonatal infection associated with ...</td>\n",
       "      <td>neonatal infection associated with intrapartum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Why is additional research needed?</td>\n",
       "      <td>First cases of coronavirus disease 2019 (COVID...</td>\n",
       "      <td>{'text': ['to complement surveillance data to ...</td>\n",
       "      <td>to complement surveillance data to build knowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>What can  some of the other activities of N ha...</td>\n",
       "      <td>Hantaviruses in the Americas and Their Role as...</td>\n",
       "      <td>{'text': ['to the interference with an array o...</td>\n",
       "      <td>to the interference with an array of the intra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                     Why is this approach significant?   \n",
       "1                   When was SARS-CoV first identified?   \n",
       "2     What is the amino acid similarity between IFIT...   \n",
       "3             What family of virus does MERS reside in?   \n",
       "4     How can a semi-mechanistic Bayesian hierarchic...   \n",
       "...                                                 ...   \n",
       "1995  Patients from how many medical centers were st...   \n",
       "1996  What domembers of the Roquin and Regnase famil...   \n",
       "1997                         What did the study report?   \n",
       "1998                 Why is additional research needed?   \n",
       "1999  What can  some of the other activities of N ha...   \n",
       "\n",
       "                                                context  \\\n",
       "0     Respiratory Viral Infections in Exacerbation o...   \n",
       "1     Host resilience to emerging coronaviruses\\n\\nh...   \n",
       "2     Role of S-Palmitoylation on IFITM5 for the Int...   \n",
       "3     Host resilience to emerging coronaviruses\\n\\nh...   \n",
       "4     Estimating the number of infections and the im...   \n",
       "...                                                 ...   \n",
       "1995  Which Kind of Provider’s Operation Volumes Mat...   \n",
       "1996  Frontiers in antiviral therapy and immunothera...   \n",
       "1997  Chikungunya: A Potentially Emerging Epidemic?\\...   \n",
       "1998  First cases of coronavirus disease 2019 (COVID...   \n",
       "1999  Hantaviruses in the Americas and Their Role as...   \n",
       "\n",
       "                                                answers  \\\n",
       "0     {'text': ['due to the current scarcity of anti...   \n",
       "1            {'text': ['2003'], 'answer_start': [1375]}   \n",
       "2     {'text': ['~ 65% similarity'], 'answer_start':...   \n",
       "3     {'text': ['coronavirus'], 'answer_start': [1018]}   \n",
       "4     {'text': ['calculating backwards from the deat...   \n",
       "...                                                 ...   \n",
       "1995           {'text': ['19'], 'answer_start': [9132]}   \n",
       "1996  {'text': ['promote or effect degradation of mR...   \n",
       "1997  {'text': ['neonatal infection associated with ...   \n",
       "1998  {'text': ['to complement surveillance data to ...   \n",
       "1999  {'text': ['to the interference with an array o...   \n",
       "\n",
       "                                                 answer  \n",
       "0     due to the current scarcity of antiviral drugs...  \n",
       "1                                                  2003  \n",
       "2                                      ~ 65% similarity  \n",
       "3                                           coronavirus  \n",
       "4     calculating backwards from the deaths observed...  \n",
       "...                                                 ...  \n",
       "1995                                                 19  \n",
       "1996  promote or effect degradation of mRNAs harbour...  \n",
       "1997  neonatal infection associated with intrapartum...  \n",
       "1998  to complement surveillance data to build knowl...  \n",
       "1999  to the interference with an array of the intra...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answer_from_list(covidqa_qa_dataset, \"answers\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mlqa\"\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "config = \"mlqa-translate-test.ar\"\n",
    "\n",
    "mlqa_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, config, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is your look district located?</td>\n",
       "      <td>Donetsk () is a district (Province) in the Sou...</td>\n",
       "      <td>{'answer_start': [-1], 'text': ['South East Uk...</td>\n",
       "      <td>South East Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does the term \"hrs\" mean?</td>\n",
       "      <td>Consultancy (33 %) - the consultancy services ...</td>\n",
       "      <td>{'answer_start': [-1], 'text': ['Human resourc...</td>\n",
       "      <td>Human resources services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did james land</td>\n",
       "      <td>James traveled to Ireland - with the help of F...</td>\n",
       "      <td>{'answer_start': [64], 'text': ['March 1689..']}</td>\n",
       "      <td>March 1689..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the degree that has been achieved?</td>\n",
       "      <td>Houston replied (Houston): \" thank you Apollo ...</td>\n",
       "      <td>{'answer_start': [1259], 'text': ['master of s...</td>\n",
       "      <td>master of science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the date of Modric's first goal in 201...</td>\n",
       "      <td>On 11 September 2010, Modric scored his first ...</td>\n",
       "      <td>{'answer_start': [-1], 'text': ['September 11,...</td>\n",
       "      <td>September 11, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>What happened to the vaccine market when the t...</td>\n",
       "      <td>In the late th century, vaccines were produced...</td>\n",
       "      <td>{'answer_start': [359], 'text': ['improved']}</td>\n",
       "      <td>improved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>What is the nationality of Laura Christine K?</td>\n",
       "      <td>Christine Kreuk (born December 30, 1982 in Van...</td>\n",
       "      <td>{'answer_start': [72], 'text': ['Canada']}</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>What is the available content?</td>\n",
       "      <td>Founded on February 14, 2005, three former emp...</td>\n",
       "      <td>{'answer_start': [-1], 'text': ['Movie Clips, ...</td>\n",
       "      <td>Movie Clips, TV, music, as well as video produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>What is Roger's mother's first name in Federer?</td>\n",
       "      <td>Federer was born at Canton hospital in Basel, ...</td>\n",
       "      <td>{'answer_start': [174], 'text': ['Lynette']}</td>\n",
       "      <td>Lynette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>What do most people consist of?</td>\n",
       "      <td>Maldives culture or culture is a culture that ...</td>\n",
       "      <td>{'answer_start': [-1], 'text': ['Of Indian Ind...</td>\n",
       "      <td>Of Indian Indian origin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                  Where is your look district located?   \n",
       "1                        What does the term \"hrs\" mean?   \n",
       "2                                   When did james land   \n",
       "3            What is the degree that has been achieved?   \n",
       "4     What is the date of Modric's first goal in 201...   \n",
       "...                                                 ...   \n",
       "1995  What happened to the vaccine market when the t...   \n",
       "1996      What is the nationality of Laura Christine K?   \n",
       "1997                     What is the available content?   \n",
       "1998    What is Roger's mother's first name in Federer?   \n",
       "1999                    What do most people consist of?   \n",
       "\n",
       "                                                context  \\\n",
       "0     Donetsk () is a district (Province) in the Sou...   \n",
       "1     Consultancy (33 %) - the consultancy services ...   \n",
       "2     James traveled to Ireland - with the help of F...   \n",
       "3     Houston replied (Houston): \" thank you Apollo ...   \n",
       "4     On 11 September 2010, Modric scored his first ...   \n",
       "...                                                 ...   \n",
       "1995  In the late th century, vaccines were produced...   \n",
       "1996  Christine Kreuk (born December 30, 1982 in Van...   \n",
       "1997  Founded on February 14, 2005, three former emp...   \n",
       "1998  Federer was born at Canton hospital in Basel, ...   \n",
       "1999  Maldives culture or culture is a culture that ...   \n",
       "\n",
       "                                                answers  \\\n",
       "0     {'answer_start': [-1], 'text': ['South East Uk...   \n",
       "1     {'answer_start': [-1], 'text': ['Human resourc...   \n",
       "2      {'answer_start': [64], 'text': ['March 1689..']}   \n",
       "3     {'answer_start': [1259], 'text': ['master of s...   \n",
       "4     {'answer_start': [-1], 'text': ['September 11,...   \n",
       "...                                                 ...   \n",
       "1995      {'answer_start': [359], 'text': ['improved']}   \n",
       "1996         {'answer_start': [72], 'text': ['Canada']}   \n",
       "1997  {'answer_start': [-1], 'text': ['Movie Clips, ...   \n",
       "1998       {'answer_start': [174], 'text': ['Lynette']}   \n",
       "1999  {'answer_start': [-1], 'text': ['Of Indian Ind...   \n",
       "\n",
       "                                                 answer  \n",
       "0                                    South East Ukraine  \n",
       "1                              Human resources services  \n",
       "2                                          March 1689..  \n",
       "3                                     master of science  \n",
       "4                                    September 11, 2010  \n",
       "...                                                 ...  \n",
       "1995                                           improved  \n",
       "1996                                             Canada  \n",
       "1997  Movie Clips, TV, music, as well as video produ...  \n",
       "1998                                            Lynette  \n",
       "1999                            Of Indian Indian origin  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answer_from_list(mlqa_qa_dataset, \"answers\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mrqa\"\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "\n",
    "mrqa_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for i in range(len(mrqa_qa_dataset)):\n",
    "    curr_ans_list = mrqa_qa_dataset['answers'][i]\n",
    "    curr_ans = max(curr_ans_list, key = len)\n",
    "    answers.append(curr_ans)\n",
    "    \n",
    "mrqa_qa_dataset['answer'] = answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logi_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"lucasmccabe/logiqa\"\n",
    "column_tuple = (\"query\", \"context\", \"options\", \"correct_option\")\n",
    "\n",
    "logi_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for i in range(len(logi_qa_dataset)):\n",
    "    curr_options = logi_qa_dataset['options'][i]\n",
    "    correct_answer = int(logi_qa_dataset['correct_option'][i])\n",
    "    answers.append(curr_options[correct_answer])\n",
    "    \n",
    "logi_qa_dataset['answer'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_qa_dataset = logi_qa_dataset.rename(columns={\"query\": \"question\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subjqa - grocery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"subjqa\"\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "config = \"grocery\"\n",
    "\n",
    "subjqa_grocery_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, config, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where i can find a new kernel?</td>\n",
       "      <td>I made this on the stovetop using an older sty...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How is amount?</td>\n",
       "      <td>These Peeled Snacks Organic Apple Clusters are...</td>\n",
       "      <td>{'text': ['the serving size is extremely small...</td>\n",
       "      <td>the serving size is extremely small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How is the calorie?</td>\n",
       "      <td>I was attracted to this product because I've b...</td>\n",
       "      <td>{'text': ['120 calories'], 'answer_start': [26...</td>\n",
       "      <td>120 calories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How is the sauce?</td>\n",
       "      <td>My whole family really enjoyed this kit. The s...</td>\n",
       "      <td>{'text': ['The sauce was fresh', 'and super ea...</td>\n",
       "      <td>and super easy to make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did you think about the selection?</td>\n",
       "      <td>I have to say that I was surprisingly impresse...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>How natural does it taste?</td>\n",
       "      <td>I can't say this tastes like apples but it doe...</td>\n",
       "      <td>{'text': ['I can't say this tastes like apples...</td>\n",
       "      <td>I can't say this tastes like apples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>What is the quality of the blend?</td>\n",
       "      <td>Vanilla to me is like licorice: one of those f...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>How do you like the texture?</td>\n",
       "      <td>I grew up on homemade andamaranth graham crack...</td>\n",
       "      <td>{'text': ['andamaranth', 'The flavor and textu...</td>\n",
       "      <td>The flavor and texture more than makes up for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>Is that a cup of coffee?</td>\n",
       "      <td>As in, I think I need to double the amount of ...</td>\n",
       "      <td>{'text': ['I think I need to double the amount...</td>\n",
       "      <td>I think I need to double the amount of coffee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>How is it bag ?</td>\n",
       "      <td>Okay, first, you need to know that I usually d...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    question  \\\n",
       "0             Where i can find a new kernel?   \n",
       "1                             How is amount?   \n",
       "2                        How is the calorie?   \n",
       "3                          How is the sauce?   \n",
       "4     How did you think about the selection?   \n",
       "...                                      ...   \n",
       "1119              How natural does it taste?   \n",
       "1120       What is the quality of the blend?   \n",
       "1121            How do you like the texture?   \n",
       "1122                Is that a cup of coffee?   \n",
       "1123                         How is it bag ?   \n",
       "\n",
       "                                                context  \\\n",
       "0     I made this on the stovetop using an older sty...   \n",
       "1     These Peeled Snacks Organic Apple Clusters are...   \n",
       "2     I was attracted to this product because I've b...   \n",
       "3     My whole family really enjoyed this kit. The s...   \n",
       "4     I have to say that I was surprisingly impresse...   \n",
       "...                                                 ...   \n",
       "1119  I can't say this tastes like apples but it doe...   \n",
       "1120  Vanilla to me is like licorice: one of those f...   \n",
       "1121  I grew up on homemade andamaranth graham crack...   \n",
       "1122  As in, I think I need to double the amount of ...   \n",
       "1123  Okay, first, you need to know that I usually d...   \n",
       "\n",
       "                                                answers  \\\n",
       "0     {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "1     {'text': ['the serving size is extremely small...   \n",
       "2     {'text': ['120 calories'], 'answer_start': [26...   \n",
       "3     {'text': ['The sauce was fresh', 'and super ea...   \n",
       "4     {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "...                                                 ...   \n",
       "1119  {'text': ['I can't say this tastes like apples...   \n",
       "1120  {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "1121  {'text': ['andamaranth', 'The flavor and textu...   \n",
       "1122  {'text': ['I think I need to double the amount...   \n",
       "1123  {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "\n",
       "                                                 answer  \n",
       "0                                                        \n",
       "1                   the serving size is extremely small  \n",
       "2                                          120 calories  \n",
       "3                                and super easy to make  \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "1119                I can't say this tastes like apples  \n",
       "1120                                                     \n",
       "1121  The flavor and texture more than makes up for ...  \n",
       "1122  I think I need to double the amount of coffee ...  \n",
       "1123                                                     \n",
       "\n",
       "[1124 rows x 4 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answer_from_list(subjqa_grocery_qa_dataset, \"answers\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subjqa - restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"subjqa\"\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "config = \"restaurants\"\n",
    "\n",
    "subjqa_restaurants_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, config, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you have a good working atmosphere?</td>\n",
       "      <td>I've been wanting to go for the longest time, ...</td>\n",
       "      <td>{'text': ['It is a loud and fun environment', ...</td>\n",
       "      <td>It is a loud and fun environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the burgers like in this spot?</td>\n",
       "      <td>A few foodie coworkers of mine read the glowin...</td>\n",
       "      <td>{'text': ['which tasted perfectly fine, but it...</td>\n",
       "      <td>which tasted perfectly fine, but it wasn't as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How is the seat?</td>\n",
       "      <td>Gluten free fried chicken and waffles!?! Yes p...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is the poutine in the menu?</td>\n",
       "      <td>$28 for a dozen wings?!! Seriously!!!!!? Their...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do they have a variety of salad?</td>\n",
       "      <td>I went on a Sunday night for dinner. They have...</td>\n",
       "      <td>{'text': ['but it's a great place for a date o...</td>\n",
       "      <td>but it's a great place for a date or a fancy d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>How is the vibe for this game?</td>\n",
       "      <td>I'm not much of a sports guy, but even I can s...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>How is the atmosphere?</td>\n",
       "      <td>Always a good to time at Nome! Great food, gre...</td>\n",
       "      <td>{'text': ['the environment is amazing'], 'answ...</td>\n",
       "      <td>the environment is amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>How is the price?</td>\n",
       "      <td>Delish! We get a variety of dishes all the tim...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>How is the sauce in that restaurant?</td>\n",
       "      <td>It's really diffcult for me to figure out how ...</td>\n",
       "      <td>{'text': [], 'answer_start': [], 'answer_subj_...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>How many food do you offer per day?</td>\n",
       "      <td>Great atmosphere, and decor. I was here for a ...</td>\n",
       "      <td>{'text': ['yet not much attention has been put...</td>\n",
       "      <td>yet not much attention has been put on the foo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  \\\n",
       "0      Do you have a good working atmosphere?   \n",
       "1     What are the burgers like in this spot?   \n",
       "2                            How is the seat?   \n",
       "3                 Is the poutine in the menu?   \n",
       "4            Do they have a variety of salad?   \n",
       "...                                       ...   \n",
       "1395           How is the vibe for this game?   \n",
       "1396                   How is the atmosphere?   \n",
       "1397                        How is the price?   \n",
       "1398     How is the sauce in that restaurant?   \n",
       "1399      How many food do you offer per day?   \n",
       "\n",
       "                                                context  \\\n",
       "0     I've been wanting to go for the longest time, ...   \n",
       "1     A few foodie coworkers of mine read the glowin...   \n",
       "2     Gluten free fried chicken and waffles!?! Yes p...   \n",
       "3     $28 for a dozen wings?!! Seriously!!!!!? Their...   \n",
       "4     I went on a Sunday night for dinner. They have...   \n",
       "...                                                 ...   \n",
       "1395  I'm not much of a sports guy, but even I can s...   \n",
       "1396  Always a good to time at Nome! Great food, gre...   \n",
       "1397  Delish! We get a variety of dishes all the tim...   \n",
       "1398  It's really diffcult for me to figure out how ...   \n",
       "1399  Great atmosphere, and decor. I was here for a ...   \n",
       "\n",
       "                                                answers  \\\n",
       "0     {'text': ['It is a loud and fun environment', ...   \n",
       "1     {'text': ['which tasted perfectly fine, but it...   \n",
       "2     {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "3     {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "4     {'text': ['but it's a great place for a date o...   \n",
       "...                                                 ...   \n",
       "1395  {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "1396  {'text': ['the environment is amazing'], 'answ...   \n",
       "1397  {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "1398  {'text': [], 'answer_start': [], 'answer_subj_...   \n",
       "1399  {'text': ['yet not much attention has been put...   \n",
       "\n",
       "                                                 answer  \n",
       "0                      It is a loud and fun environment  \n",
       "1     which tasted perfectly fine, but it wasn't as ...  \n",
       "2                                                        \n",
       "3                                                        \n",
       "4     but it's a great place for a date or a fancy d...  \n",
       "...                                                 ...  \n",
       "1395                                                     \n",
       "1396                         the environment is amazing  \n",
       "1397                                                     \n",
       "1398                                                     \n",
       "1399  yet not much attention has been put on the foo...  \n",
       "\n",
       "[1400 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answer_from_list(subjqa_restaurants_qa_dataset, \"answers\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [bioasq_dataset, pubmed_qa_dataset, squad_qa_dataset, sciq_qa_dataset, covidqa_qa_dataset, \n",
    "                mlqa_qa_dataset, mrqa_qa_dataset, logi_qa_dataset, subjqa_grocery_qa_dataset, subjqa_restaurants_qa_dataset]\n",
    "\n",
    "dataset_list_names = [\"bioasq_dataset\", \"pubmed_qa_dataset\", \"squad_qa_dataset\", \"sciq_qa_dataset\", \"covidqa_qa_dataset\", \n",
    "                \"mlqa_qa_dataset\", \"mrqa_qa_dataset\", \"logi_qa_dataset\", \"subjqa_grocery_qa_dataset\", \"subjqa_restaurants_qa_dataset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Dataset Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\"context\", \"question\", \"answer\"]\n",
    "\n",
    "for i in range(len(dataset_list)):\n",
    "    dataset_list[i] = extract_relevant_columns(dataset_list[i], column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding domains of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/638563115.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[0][\"domain\"] = \"bio\"\n",
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/638563115.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[1][\"domain\"] = \"bio\"\n",
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/638563115.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[3][\"domain\"] = \"science\"\n",
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/638563115.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[7][\"domain\"] = \"general\"\n"
     ]
    }
   ],
   "source": [
    "dataset_list[0][\"domain\"] = \"bio\"\n",
    "dataset_list[1][\"domain\"] = \"bio\"\n",
    "dataset_list[2][\"domain\"] = \"general\"\n",
    "dataset_list[3][\"domain\"] = \"science\"\n",
    "dataset_list[4][\"domain\"] = \"bio\"\n",
    "dataset_list[5][\"domain\"] = \"general\"\n",
    "dataset_list[6][\"domain\"] = \"general\"\n",
    "dataset_list[7][\"domain\"] = \"general\"\n",
    "dataset_list[8][\"domain\"] = \"general\"\n",
    "dataset_list[9][\"domain\"] = \"general\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding names of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/3568682806.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[i][\"models\"] = \"\"\n",
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/3568682806.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[i][\"dataset\"] = dataset_list_names[i]\n",
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/3568682806.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[i][\"models\"] = \"\"\n",
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/3568682806.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[i][\"dataset\"] = dataset_list_names[i]\n",
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/3568682806.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[i][\"models\"] = \"\"\n",
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/3568682806.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_list[i][\"dataset\"] = dataset_list_names[i]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset_list)):\n",
    "    dataset_list[i][\"models\"] = \"\"\n",
    "    dataset_list[i][\"dataset\"] = dataset_list_names[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding models to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/qvlzh6f55g9btg0ghgfd294w0000gn/T/ipykernel_52441/2845669672.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['models'] = dataset['models'].apply(lambda x: domain_model_dict[domain])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset_list)):\n",
    "    dataset = dataset_list[i]\n",
    "    domain = dataset['domain'][0]\n",
    "    \n",
    "    if domain==\"general\":\n",
    "        dataset['models'] = dataset['models'].apply(lambda x: domain_model_dict[\"None\"])\n",
    "    else:\n",
    "        dataset['models'] = dataset['models'].apply(lambda x: domain_model_dict[domain])\n",
    "    \n",
    "    dataset_list[i] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_empty_rows(dataset):\n",
    "    dataset = dataset[dataset['context']!='']\n",
    "    dataset = dataset[dataset['question']!='']\n",
    "    dataset = dataset[dataset['answer']!='']\n",
    "    return dataset\n",
    "    \n",
    "for i in range(len(dataset_list)):\n",
    "    dataset_list[i] = filter_empty_rows(dataset_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4719\n",
      "1000\n",
      "2000\n",
      "884\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "523\n",
      "598\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset_list)):\n",
    "    print(len(dataset_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lower_case(dataset):\n",
    "    dataset['question'] = dataset['question'].str.lower() \n",
    "    dataset['context'] = dataset['context'].str.lower() \n",
    "    dataset['answer'] = dataset['answer'].str.lower() \n",
    "    return dataset\n",
    "    \n",
    "for i in range(len(dataset_list)):\n",
    "    dataset_list[i] = convert_to_lower_case(dataset_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "884\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "523\n",
      "598\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset_list)):\n",
    "    print(len(dataset_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering 1000 from each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k(dataset, k):\n",
    "    dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "    dataset = dataset.head(k)\n",
    "    return dataset\n",
    "\n",
    "for i in range(len(dataset_list)):\n",
    "    dataset_list[i] = get_top_k(dataset_list[i], 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pd.concat(dataset_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9005"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = eval_dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.to_csv(\"eval_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11-632",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
