{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rows_from_dataset(dataset: str,\n",
    "                             column_names: tuple,\n",
    "                             *args,\n",
    "                             num_samples: int = 100,\n",
    "                             seed: int = 42,\n",
    "                             **kwargs) -> pd.DataFrame:    \n",
    "    if not isinstance(column_names, tuple):\n",
    "        raise Exception(\"Column names need to be a list of column names as strings.\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset, *args, split=\"test\")\n",
    "    except Exception as e:\n",
    "        print(\"Could NOT load dataset for {0}\".format(dataset))\n",
    "        raise Exception(\"Error while loading dataset {}\".format(e))\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed)\n",
    "    df = pd.DataFrame(shuffled_dataset[:num_samples])\n",
    "    try:\n",
    "        return df[list(column_names)]\n",
    "    except KeyError as e:\n",
    "        raise e\n",
    "    \n",
    "    \n",
    "def sample_rows_from_dataset(dataset: str,\n",
    "                             column_names: tuple,\n",
    "                             *args,\n",
    "                             num_samples: int = 250,\n",
    "                             seed: int = 42,\n",
    "                             **kwargs) -> pd.DataFrame:\n",
    "    if not isinstance(column_names, tuple):\n",
    "        raise Exception(\"Column names need to be a list of column names as strings.\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset, *args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(\"Could NOT load dataset for {0}\".format(dataset))\n",
    "        raise Exception(\"Error while loading dataset {}\".format(e))\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed)\n",
    "    df = pd.DataFrame(shuffled_dataset[:num_samples])\n",
    "    try:\n",
    "        return df[list(column_names)]\n",
    "    except KeyError as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"squad\"\n",
    "configs = None\n",
    "column_tuple = (\"question\", \"context\")\n",
    "\n",
    "squad_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pubmed Biology Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 11.1k/11.1k [00:00<00:00, 22.4MB/s]\n",
      "Downloading metadata: 100%|██████████| 12.7k/12.7k [00:00<00:00, 27.1MB/s]\n",
      "Downloading readme: 100%|██████████| 4.59k/4.59k [00:00<00:00, 15.5MB/s]\n",
      "Downloading data: 2.58MB [00:00, 5.03MB/s]/3 [00:00<?, ?it/s]\n",
      "Downloading data: 100%|██████████| 152M/152M [00:05<00:00, 28.5MB/s]]\n",
      "Downloading data: 100%|██████████| 533M/533M [00:14<00:00, 37.6MB/s]]\n",
      "Downloading data files: 100%|██████████| 3/3 [00:22<00:00,  7.47s/it]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 229.01it/s]\n",
      "Generating train split: 100%|██████████| 1000/1000 [00:00<00:00, 4525.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"pubmed_qa\"\n",
    "config = \"pqa_labeled\"\n",
    "column_tuple = (\"question\", \"context\")\n",
    "\n",
    "pubmed_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, config, split=\"train\")\n",
    "\n",
    "contexts_strings = []\n",
    "\n",
    "for i in range(len(pubmed_qa_dataset)):\n",
    "    contexts_strings.append(' '.join(pubmed_qa_dataset[\"context\"][i]['contexts']))\n",
    "    \n",
    "pubmed_qa_dataset['context'] = contexts_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioASQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 14.0k/14.0k [00:00<00:00, 40.1MB/s]\n",
      "Downloading data: 100%|██████████| 7.12G/7.12G [09:22<00:00, 12.7MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [09:22<00:00, 562.45s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [01:16<00:00, 76.97s/it]\n",
      "Generating train split: 14100000 examples [01:29, 158196.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"BeIR/bioasq-generated-queries\"\n",
    "column_tuple = (\"text\", \"query\")\n",
    "\n",
    "bioasq_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")\n",
    "bioasq_qa_dataset = bioasq_qa_dataset.rename(columns={\"text\": \"context\", \"query\": \"question\"})\n",
    "bioasq_qa_dataset = bioasq_qa_dataset[[\"question\", \"context\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuad (legal) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.19k/5.19k [00:00<00:00, 21.7MB/s]\n",
      "Downloading metadata: 100%|██████████| 1.91k/1.91k [00:00<00:00, 21.8MB/s]\n",
      "Downloading readme: 100%|██████████| 15.5k/15.5k [00:00<00:00, 21.3MB/s]\n",
      "Downloading data: 100%|██████████| 18.3M/18.3M [00:05<00:00, 3.26MB/s]\n",
      "Generating train split: 100%|██████████| 22450/22450 [00:01<00:00, 12300.53 examples/s]\n",
      "Generating test split: 100%|██████████| 4182/4182 [00:00<00:00, 15362.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"cuad\"\n",
    "column_tuple = (\"question\", \"context\")\n",
    "\n",
    "cuad_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuad_qa_dataset[\"domain\"] = \"legal\"\n",
    "bioasq_qa_dataset[\"domain\"] = \"bio\"\n",
    "pubmed_qa_dataset[\"domain\"] = \"bio\"\n",
    "squad_qa_dataset[\"domain\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pd.concat([cuad_qa_dataset, bioasq_qa_dataset, pubmed_qa_dataset, squad_qa_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.to_csv(\"eval_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11-632",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
