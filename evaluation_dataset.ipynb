{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_directory = os.path.abspath('') + \"/repository\"\n",
    "models_jsons = os.listdir(repository_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_model_dict = {}\n",
    "\n",
    "for model_file in models_jsons:\n",
    "    with open(repository_directory + \"/\" + model_file) as model_json:\n",
    "        data = json.load(model_json)\n",
    "        for dataset in data['dataset']:\n",
    "            if dataset not in dataset_model_dict:\n",
    "                dataset_model_dict[dataset] = []\n",
    "            \n",
    "            dataset_model_dict[dataset].append(data['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'squad_v2': ['mrm8488/longformer-base-4096-finetuned-squadv2',\n",
       "  'allenai/unifiedqa-t5-base',\n",
       "  'ixa-ehu/SciBERT-SQuAD-QuAC'],\n",
       " 'hotpot_qa': ['AdapterHub/roberta-base-pf-hotpotqa'],\n",
       " 'cuad': ['Rakib/roberta-base-on-cuad', 'akdeniz27/deberta-v2-xlarge-cuad'],\n",
       " 'trivia_qa': ['allenai/longformer-large-4096-finetuned-triviaqa'],\n",
       " 'squad': ['ozcangundes/T5-base-for-BioQA',\n",
       "  'MaRiOrOsSi/t5-base-finetuned-question-answering',\n",
       "  'vanadhi/roberta-base-fiqa-flm-sq-flit'],\n",
       " 'BeIR/bioasq-generated-queries': ['ozcangundes/T5-base-for-BioQA'],\n",
       " 'duorc': ['MaRiOrOsSi/t5-base-finetuned-question-answering',\n",
       "  'MaRiOrOsSi/t5-base-finetuned-question-answering'],\n",
       " 'pubmed_qa': ['razent/SciFive-base-Pubmed_PMC', 'microsoft/biogpt'],\n",
       " 'zhengyun21/PMC-Patients': ['razent/SciFive-base-Pubmed_PMC'],\n",
       " 'boolq': ['allenai/unifiedqa-t5-base'],\n",
       " 'race': ['allenai/unifiedqa-t5-base'],\n",
       " 'quoref': ['allenai/unifiedqa-t5-base'],\n",
       " 'ropes': ['allenai/unifiedqa-t5-base'],\n",
       " 'drop': ['allenai/unifiedqa-t5-base'],\n",
       " 'sagnikrayc/mctest': ['allenai/unifiedqa-t5-base'],\n",
       " 'qasc': ['allenai/unifiedqa-t5-base'],\n",
       " 'math_qa': ['AlexWortega/taskGPT2-xl-v0.2a'],\n",
       " 'gsm8k': ['AlexWortega/taskGPT2-xl-v0.2a'],\n",
       " 'covid_qa_deepset': ['Sarmila/pubmed-bert-squad-covidqa'],\n",
       " 'quac': ['ixa-ehu/SciBERT-SQuAD-QuAC']}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/siddharth/Desktop/capstone/repository'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rows_from_dataset(dataset: str,\n",
    "                             column_names: tuple,\n",
    "                             *args,\n",
    "                             num_samples: int = 250,\n",
    "                             seed: int = 42,\n",
    "                             **kwargs) -> pd.DataFrame:    \n",
    "    if not isinstance(column_names, tuple):\n",
    "        raise Exception(\"Column names need to be a list of column names as strings.\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset, *args, split=\"test\")\n",
    "    except Exception as e:\n",
    "        print(\"Could NOT load dataset for {0}\".format(dataset))\n",
    "        raise Exception(\"Error while loading dataset {}\".format(e))\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed)\n",
    "    df = pd.DataFrame(shuffled_dataset[:num_samples])\n",
    "    try:\n",
    "        return df[list(column_names)]\n",
    "    except KeyError as e:\n",
    "        raise e\n",
    "    \n",
    "    \n",
    "def sample_rows_from_dataset(dataset: str,\n",
    "                             column_names: tuple,\n",
    "                             *args,\n",
    "                             num_samples: int = 3000,\n",
    "                             seed: int = 42,\n",
    "                             **kwargs) -> pd.DataFrame:\n",
    "    if not isinstance(column_names, tuple):\n",
    "        raise Exception(\"Column names need to be a list of column names as strings.\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset, *args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(\"Could NOT load dataset for {0}\".format(dataset))\n",
    "        raise Exception(\"Error while loading dataset {}\".format(e))\n",
    "    shuffled_dataset = dataset.shuffle(seed=seed)\n",
    "    df = pd.DataFrame(shuffled_dataset[:num_samples])\n",
    "    try:\n",
    "        return df[list(column_names)]\n",
    "    except KeyError as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"squad\"\n",
    "configs = None\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "\n",
    "squad_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for i in range(len(squad_qa_dataset)):\n",
    "    curr_ans_list = squad_qa_dataset['answers'][i]['text']\n",
    "    curr_ans = max(curr_ans_list, key = len)\n",
    "    answers.append(curr_ans)\n",
    "    \n",
    "squad_qa_dataset['answers'] = answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pubmed Biology Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"pubmed_qa\"\n",
    "config = \"pqa_labeled\"\n",
    "column_tuple = (\"question\", \"context\", \"long_answer\")\n",
    "\n",
    "pubmed_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, config, split=\"train\")\n",
    "\n",
    "contexts_strings = []\n",
    "\n",
    "for i in range(len(pubmed_qa_dataset)):\n",
    "    contexts_strings.append(' '.join(pubmed_qa_dataset[\"context\"][i]['contexts']))\n",
    "    \n",
    "pubmed_qa_dataset['context'] = contexts_strings\n",
    "pubmed_qa_dataset = pubmed_qa_dataset.rename(columns={\"long_answer\": \"answers\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioASQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 14.0k/14.0k [00:00<00:00, 40.1MB/s]\n",
      "Downloading data: 100%|██████████| 7.12G/7.12G [09:22<00:00, 12.7MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [09:22<00:00, 562.45s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [01:16<00:00, 76.97s/it]\n",
      "Generating train split: 14100000 examples [01:29, 158196.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"BeIR/bioasq-generated-queries\"\n",
    "column_tuple = (\"text\", \"query\")\n",
    "\n",
    "bioasq_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")\n",
    "bioasq_qa_dataset = bioasq_qa_dataset.rename(columns={\"text\": \"context\", \"query\": \"question\"})\n",
    "bioasq_qa_dataset = bioasq_qa_dataset[[\"question\", \"context\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuad (legal) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cuad\"\n",
    "column_tuple = (\"question\", \"context\", \"answers\")\n",
    "\n",
    "cuad_qa_dataset = sample_rows_from_dataset(dataset_name, column_tuple, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for i in range(len(cuad_qa_dataset)):\n",
    "    curr_ans_list = cuad_qa_dataset['answers'][i]['text']\n",
    "    if len(curr_ans_list)!=0:\n",
    "        curr_ans = max(curr_ans_list, key = len)\n",
    "    else:\n",
    "        curr_ans = \"\"\n",
    "    answers.append(curr_ans)\n",
    "    \n",
    "cuad_qa_dataset['answers'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuad_qa_dataset = cuad_qa_dataset[cuad_qa_dataset[\"answers\"]!=\"\"][:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuad_qa_dataset[\"domain\"] = \"legal\"\n",
    "#bioasq_qa_dataset[\"domain\"] = \"bio\"\n",
    "pubmed_qa_dataset[\"domain\"] = \"bio\"\n",
    "squad_qa_dataset[\"domain\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pd.concat([cuad_qa_dataset, pubmed_qa_dataset, squad_qa_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.to_csv(\"eval_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11-632",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
